# ==============================================================================
# COAZ CHATBOT ENVIRONMENT CONFIGURATION
# ==============================================================================

# AI Provider Configuration
# Options: 'ai_horde', 'transformers_js', 'mock'
AI_PROVIDER=ai_horde

# Fallback to mock responses if AI fails
AI_FALLBACK_TO_MOCK=true

# AI System Configuration
AI_TIMEOUT=15000
AI_MAX_RETRIES=2

# Working AI Providers:
# - ai_horde: Free AI Horde service (works without API key)
# - transformers_js: Local models via Transformers.js (requires download)
# - mock: Intelligent pattern-based responses (always works)

# Note: Removed Hugging Face and individual model configs
# The new system uses direct endpoints and fallback patterns

# Server Configuration
PORT=8080

# Environment (development, staging, production)
NODE_ENV=development

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,https://coaz.org

# Conversation Management
MAX_CONVERSATION_HISTORY=20
SESSION_TIMEOUT_MINUTES=60

# Rate Limiting
RATE_LIMIT_WINDOW_MINUTES=15
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
ENABLE_REQUEST_LOGGING=true

# PDF Processing
CONSTITUTION_PDF_PATH=./constitution.pdf

# Website Scraping
WEB_SCRAPING_ENABLED=true
COAZ_WEBSITE_URL=https://coaz.org
WEB_CACHE_TIMEOUT=3600000
USE_JS_RENDERING=false
ENHANCED_EXTRACTION=true
WEBSITE_INDEX_PATH=./website-index.json

# ==============================================================================
# SETUP INSTRUCTIONS:
# ==============================================================================
# 1. This file has been created with default settings
# 2. Modify AI_PROVIDER to switch between models: llama3, flan-t5, gpt-j, phi-4
# 3. Add HUGGING_FACE_API_KEY for better performance (optional)
# 4. Adjust model parameters as needed
# 5. Run with: npm run start-simple
# ==============================================================================